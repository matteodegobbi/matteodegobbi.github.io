<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Deep Learning on Matteo De Gobbi</title><link>https://matteodegobbi.github.io/categories/deep-learning/</link><description>Recent content in Deep Learning on Matteo De Gobbi</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Wed, 18 Jun 2025 02:06:47 +0200</lastBuildDate><atom:link href="https://matteodegobbi.github.io/categories/deep-learning/index.xml" rel="self" type="application/rss+xml"/><item><title>Paper on Insect Species and Genus Classification ğŸğŸğŸ›</title><link>https://matteodegobbi.github.io/p/paper-on-insect-species-and-genus-classification/</link><pubDate>Wed, 18 Jun 2025 00:51:54 +0200</pubDate><guid>https://matteodegobbi.github.io/p/paper-on-insect-species-and-genus-classification/</guid><description>&lt;img src="https://matteodegobbi.github.io/p/paper-on-insect-species-and-genus-classification/img.png" alt="Featured image of post Paper on Insect Species and Genus Classification ğŸğŸğŸ›" />&lt;p>In February of this year we published a &lt;a class="link" href="https://www.mdpi.com/1999-4893/18/2/105" target="_blank" rel="noopener"
>paper&lt;/a> on undescribed Insect species and genus classification using DNA and image data.&lt;/p>
&lt;p>My main contributions, together with Roger, were:&lt;/p>
&lt;ul>
&lt;li>ReACGAN for image feature extraction&lt;/li>
&lt;li>CNN model with vertical kernels for DNA feature extraction&lt;/li>
&lt;li>Compiling of finetuning dataset for the ReACGAN and CNN, scraping data from BOLDSystemsV3. (Image+DNA)&lt;/li>
&lt;li>Compiling of pretraining dataset for the ReACGAN, merging previous datasets. (Only Image)&lt;/li>
&lt;li>Replicating a previous study on the new dataset, since the dataset of the original paper is not publicly available&lt;/li>
&lt;/ul>
&lt;p>The finetuning dataset can be found at: &lt;a class="link" href="https://zenodo.org/records/14277812" target="_blank" rel="noopener"
>https://zenodo.org/records/14277812&lt;/a>&lt;br>
The pretraining dataset can be found at: &lt;a class="link" href="https://zenodo.org/records/14577906" target="_blank" rel="noopener"
>https://zenodo.org/records/14577906&lt;/a>&lt;br>
The code can be found at: &lt;a class="link" href="https://github.com/matteodegobbi/InsectClassification" target="_blank" rel="noopener"
>https://github.com/matteodegobbi/InsectClassification&lt;/a>&lt;br>
Paper: &lt;a class="link" href="https://www.mdpi.com/1999-4893/18/2/105" target="_blank" rel="noopener"
>https://www.mdpi.com/1999-4893/18/2/105&lt;/a>\&lt;/p></description></item><item><title>First place winner of AI Pro Competition ğŸ†</title><link>https://matteodegobbi.github.io/p/first-place-winner-of-ai-pro-competition/</link><pubDate>Wed, 18 Jun 2025 02:06:47 +0200</pubDate><guid>https://matteodegobbi.github.io/p/first-place-winner-of-ai-pro-competition/</guid><description>&lt;img src="https://matteodegobbi.github.io/p/first-place-winner-of-ai-pro-competition/cnosso.jpg" alt="Featured image of post First place winner of AI Pro Competition ğŸ†" />&lt;p>This June I took part in the Digital Skills Cup AI Pro 2025, an online trivia competition about AI and Deep Learning hosted by LLPA. I got first place in the national qualification and then I also got first place in the world competition!&lt;/p>
&lt;p>I won a prize of 3000$ to use to travel abroad fully paid by LLPA.&lt;/p>
&lt;p>I visited Crete with my girlfriend, we had a lot of fun and it was a very entertaining experience participating in this competition.&lt;/p>
&lt;p>Linkedin post about the competition: &lt;a class="link" href="https://www.linkedin.com/feed/update/urn:li:activity:7355870715205533698/" target="_blank" rel="noopener"
>https://www.linkedin.com/feed/update/urn:li:activity:7355870715205533698/&lt;/a>&lt;/p>
&lt;figure>
&lt;img src="https://matteodegobbi.github.io/llpa_crete/grotta.jpg" style="width:800px;" alt="Image 1">
&lt;img src="https://matteodegobbi.github.io/llpa_crete/spiaggia.jpg" style="width:600px;" alt="Image 1">
&lt;/figure></description></item><item><title>Reinforcement learning agent for Cave Descent game at HackUPC 2025</title><link>https://matteodegobbi.github.io/p/reinforcement-learning-agent-for-cave-descent-game-at-hackupc-2025/</link><pubDate>Sun, 15 Jun 2025 01:27:57 +0200</pubDate><guid>https://matteodegobbi.github.io/p/reinforcement-learning-agent-for-cave-descent-game-at-hackupc-2025/</guid><description>&lt;img src="https://matteodegobbi.github.io/p/reinforcement-learning-agent-for-cave-descent-game-at-hackupc-2025/img.png" alt="Featured image of post Reinforcement learning agent for Cave Descent game at HackUPC 2025" />&lt;p>This May I partecipatd at &lt;a class="link" href="https://hackupc.com/" target="_blank" rel="noopener"
>HackUPC 2025&lt;/a>, an hackhathon organized by FIB in Barcelona.&lt;/p>
&lt;p>Together with &lt;a class="link" href="https://vojtechbestak.cz/" target="_blank" rel="noopener"
>VojtÄ›ch&lt;/a>, we built a reinforcement learning agent that learns to play a game similar to Geometry Dash&amp;rsquo;s rocket section.
The agent is trained using deep Q-Learning and we built the game using pygame.&lt;/p>
&lt;p>We managed to get in the top 5 and present our work in front of everyone ğŸ˜!&lt;/p>
&lt;p>Devpost: &lt;a class="link" href="https://devpost.com/software/rocket-deep-reinforcement-learning" target="_blank" rel="noopener"
>https://devpost.com/software/rocket-deep-reinforcement-learning&lt;/a>&lt;br>
Code: &lt;a class="link" href="https://github.com/matteodegobbi/CaveDescentRL" target="_blank" rel="noopener"
>https://github.com/matteodegobbi/CaveDescentRL&lt;/a>&lt;br>
VojtÄ›ch&amp;rsquo;s webiste: &lt;a class="link" href="https://vojtechbestak.cz/" target="_blank" rel="noopener"
>https://vojtechbestak.cz/&lt;/a>\&lt;/p>
&lt;figure>
&lt;figcaption>Me and VojtÄ›ch explaining our project&lt;/figcaption>
&lt;img src="https://matteodegobbi.github.io/misc/hack.jpg" style="width:500px;" alt="Image 1">
&lt;/figure></description></item><item><title>Dataset Inference attacks for Generative Adversarial Networks ğŸ¤–</title><link>https://matteodegobbi.github.io/p/dataset-inference-attacks-for-generative-adversarial-networks/</link><pubDate>Mon, 16 Oct 2023 02:06:54 +0200</pubDate><guid>https://matteodegobbi.github.io/p/dataset-inference-attacks-for-generative-adversarial-networks/</guid><description>&lt;img src="https://matteodegobbi.github.io/gan.png" alt="Featured image of post Dataset Inference attacks for Generative Adversarial Networks ğŸ¤–" />&lt;p>In my bachelor&amp;rsquo;s thesis I explored the idea of membership inference attacks, where we try to determine whether a given sample was present in the training set of a neural network without having access to the weights of the neural network itself. In particular I targeted Generative Adversarial Networks where the training data can contain sensitive information, especially in the medical setting, in forensics and criminal justice.&lt;/p>
&lt;p>The full thesis can be found at: &lt;a class="link" href="https://thesis.unipd.it/handle/20.500.12608/57083" target="_blank" rel="noopener"
>https://thesis.unipd.it/handle/20.500.12608/57083&lt;/a>&lt;/p>
&lt;h2 id="abstract">Abstract:
&lt;/h2>&lt;p>Generative Adversarial Networks (GANs) have had great success in the generation of artifical samples from datasets made of sensitive data which can&amp;rsquo;t be disclosed publicly. These GANs, if released to the public, could allow an attacker to leak sensitive information from the GAN&amp;rsquo;s training dataset. We analize a type of attack called Membership Inference Attack (MIA), which consists of determining the membership of a certain sample to the training set of the GAN. We analize the success of both black box and white box Membership Inference Attacks on GANs trained on MNIST and anime faces. We look for a relationship between the precision of the attacks and the several hyperparameters of the GANs such as: amount of images in the training set, number of epochs of training, quality of generated images, number of generated images available to the attacker. We show how an insufficient number of training images or an excessive number of training epochs causes overfitting in the GAN, which is then vulnerable to MIAs. We analize how the FrÃ©chet&amp;rsquo;s Inception Distance (FID) between the set of generated images and the original training set impacts on the success of the MIAs.&lt;/p></description></item></channel></rss>